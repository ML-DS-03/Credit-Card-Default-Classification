{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYb7nfnTtDHTOZem2pYJqi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ML-DS-03/Credit-Card-Default-Classification/blob/main/Churn_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kLgRcuHUKkIH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, sys, re, ast, csv, math, gc, random, enum, argparse, json, requests, time  \n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None) # to ensure console display all columns\n",
        "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
        "pd.set_option('display.max_row', 40)\n",
        "plt.style.use('ggplot')\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "from joblib import dump, load\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyxlsb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jBdFQ1XL3I5",
        "outputId": "7543c9b6-3324-485b-e52a-674491f27905"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyxlsb\n",
            "  Downloading pyxlsb-1.0.9-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyxlsb\n",
            "Successfully installed pyxlsb-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "grfhp923MuNh",
        "outputId": "17a03791-979d-456e-bb48-41470a078327"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-219bbe1d-197e-43fa-ae39-b0509387bf58\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-219bbe1d-197e-43fa-ae39-b0509387bf58\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving PoliciesFinal.xlsb to PoliciesFinal.xlsb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "data_df = pd.read_excel(io.BytesIO(uploaded['PoliciesFinal.xlsb']))"
      ],
      "metadata": {
        "id": "18rc5Wl3QISA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0ROutTJLslF",
        "outputId": "7d2cd4fc-0cc5-469f-f865-b71aa460e17a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.5-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pygam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DUCyaBPLymM",
        "outputId": "0028534b-323e-4927-9113-ca2b4f5188c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygam\n",
            "  Downloading pygam-0.8.0-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |▌                               | 30 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 92 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 122 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 133 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 143 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 153 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 163 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 174 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 184 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 194 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 204 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 215 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 225 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 235 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 245 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 256 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 266 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 276 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 286 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 296 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 307 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 317 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 327 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 337 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 348 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 358 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 368 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 378 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 389 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 399 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 409 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 419 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 430 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 440 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 450 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 460 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 471 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 481 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 491 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 501 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 512 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 522 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 532 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 542 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 552 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 563 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 573 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 583 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 593 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 604 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 614 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 624 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 634 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 645 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 655 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 665 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 675 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 686 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 696 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 706 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 716 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 727 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 737 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 747 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 757 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 768 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 778 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 788 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 798 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 808 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 819 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 829 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 839 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 849 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 860 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 870 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 880 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 890 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 901 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 911 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 921 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 931 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 942 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 952 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 962 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 972 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 983 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 993 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.0 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.0 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.0 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.0 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.0 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.3 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.3 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.3 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.3 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.4 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.4 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.4 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.4 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.4 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.5 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.5 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.5 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.5 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.5 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.6 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.6 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.6 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.6 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.6 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.7 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.7 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.7 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.7 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.7 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.7 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.7 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.8 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.8 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.8 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.8 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.8 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.8 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8 MB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pygam) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pygam) (1.4.1)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from pygam) (3.38.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pygam) (0.16.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->pygam) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from progressbar2->pygam) (1.15.0)\n",
            "Installing collected packages: pygam\n",
            "Successfully installed pygam-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyajPMbSQ__o",
        "outputId": "7159d5ef-c1c6-45fe-e26f-404f161d6b0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install glmnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7WN2xKTQ8zO",
        "outputId": "716a00e5-2076-4f1a-ffb2-9037005b4276"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting glmnet\n",
            "  Downloading glmnet-2.2.1-cp37-cp37m-manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from glmnet) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from glmnet) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from glmnet) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from glmnet) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->glmnet) (3.1.0)\n",
            "Installing collected packages: glmnet\n",
            "Successfully installed glmnet-2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import Pool, CatBoostClassifier\n",
        "from sklearn.metrics import recall_score, roc_auc_score, classification_report, precision_recall_curve, auc, accuracy_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "from glmnet import LogitNet # https://github.com/civisanalytics/python-glmnet\n",
        "from pygam import LogisticGAM, s, f # https://pygam.readthedocs.io/en/latest/notebooks/tour_of_pygam.html#\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import Dataset as lgb_Dataset\n",
        "from lightgbm import train as lgb_train\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def get_lgb_classification_model(data_df, col_target, col_feature): \n",
        "    \n",
        "    data_df_train, data_df_test = train_test_split(data_df, shuffle=True, random_state=100, stratify=data_df[col_target], test_size=0.2)    \n",
        "    train_set = lgb_Dataset(data = data_df_train[col_feature], label = data_df_train[col_target])\n",
        "    val_set = lgb_Dataset(data = data_df_test[col_feature], label = data_df_test[col_target])\n",
        "    params = {\n",
        "                'boosting_type': 'gbdt',\n",
        "                'objective': 'binary',\n",
        "                'n_jobs': 2,\n",
        "                'learning_rate': 0.1,\n",
        "                'verbose': -1,\n",
        "                'seed': 100,                   \n",
        "                }\n",
        "\n",
        "    model = None\n",
        "    model = lgb_train(params, train_set, \n",
        "                      num_boost_round=200, early_stopping_rounds=40, \n",
        "                      valid_sets = [train_set, val_set], verbose_eval=False)        \n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def get_df_woe(data_df_bin, col_bin, col_target):\n",
        "    df_woe = pd.DataFrame(columns = ['feature_bin'], data = col_bin)        \n",
        "    df_woe['feature'] = df_woe['feature_bin'].apply(lambda s: '_'.join(s.split('--_')[:-1]))    \n",
        "    df_woe['dist_good'] = 0\n",
        "    df_woe['dist_bad'] = 0    \n",
        "    \n",
        "    for feature in sorted(list(set(df_woe['feature']))):\n",
        "        \n",
        "        idx = df_woe['feature']==feature\n",
        "        feature_bin_list = list(df_woe.loc[idx,'feature_bin'])\n",
        "        df_woe.loc[idx,'dist_good'] = np.sum(np.array(data_df_bin[feature_bin_list])*(np.tile(np.array(data_df_bin[col_target]), (len(feature_bin_list),1)).T==0),axis=0)/np.sum(data_df_bin[col_target]==0)\n",
        "        df_woe.loc[idx,'dist_bad'] = np.sum(np.array(data_df_bin[feature_bin_list])*(np.tile(np.array(data_df_bin[col_target]), (len(feature_bin_list),1)).T!=0),axis=0)/np.sum(data_df_bin[col_target]!=0)\n",
        "              \n",
        "    df_woe['WOE'] = np.log(df_woe['dist_good']/df_woe['dist_bad'])*100\n",
        "    df_woe.loc[np.abs(df_woe['WOE'])==np.inf, 'WOE'] = 0\n",
        "    df_woe.loc[df_woe['WOE'].isna(), 'WOE'] = 0\n",
        "\n",
        "    woe_map_dict = {}\n",
        "    for feature in sorted(list(set(df_woe['feature']))):\n",
        "        idx = df_woe['feature']==feature\n",
        "        woe_map_dict[feature] = {}\n",
        "        for (feature_bin, woe) in zip(df_woe.loc[idx,'feature_bin'], df_woe.loc[idx,'WOE']):\n",
        "            woe_map_dict[feature][woe] = [feature_bin.split('--_')[-1]]\n",
        "\n",
        "    return (df_woe, woe_map_dict)\n",
        "\n",
        "\n",
        "\n",
        "def map_woe_df(data_df_cat, woe_map_dict):\n",
        "    \n",
        "    def map_func(s):\n",
        "        out = 0.0\n",
        "        for k in woe_map_dict[col]:\n",
        "            if s in woe_map_dict[col][k]:\n",
        "                out = k\n",
        "                break        \n",
        "        return out    \n",
        "\n",
        "    data_df_woe = data_df_cat.copy()\n",
        "    \n",
        "    for col in woe_map_dict:\n",
        "        data_df_woe[col] = data_df_woe[col].apply(lambda s: map_func(s))\n",
        "        data_df_woe[col] = data_df_woe[col].astype(np.float64)\n",
        "        \n",
        "    return data_df_woe\n",
        "\n",
        "\n",
        "\n",
        "def get_model_df(data_df, col_id, col_target, col_num, col_cat, feature_method, woe_map_dict=None):\n",
        "\n",
        "    if feature_method == 'one_hot':\n",
        "        col_init = [col_id, col_target] + col_num\n",
        "        model_df = data_df[col_init].copy()\n",
        "        for col in col_cat:\n",
        "            model_df = pd.concat([model_df, pd.get_dummies(data_df[col], prefix=f\"{col}--\")], axis=1)    \n",
        "        col_feature = [c for c in model_df.columns if c not in [col_id, col_target]]\n",
        "\n",
        "    if feature_method == 'woe':\n",
        "        col_init = [col_id, col_target] + col_num\n",
        "        \n",
        "        if woe_map_dict is None:\n",
        "            model_df = data_df[col_init].copy()\n",
        "            for col in col_cat:\n",
        "                model_df = pd.concat([model_df, pd.get_dummies(data_df[col], prefix=f\"{col}--\")], axis=1)    \n",
        "            \n",
        "            col_bin = [c for c in model_df.columns if c not in col_init]\n",
        "            data_df_bin = model_df[[col_id, col_target] + col_bin].copy()\n",
        "            (_, woe_map_dict) = get_df_woe(data_df_bin, col_bin, col_target)\n",
        "            \n",
        "        \n",
        "        data_df_cat = data_df[col_cat].copy()\n",
        "        data_df_woe = map_woe_df(data_df_cat, woe_map_dict)\n",
        "        model_df = pd.concat([data_df[col_init], data_df_woe], axis=1) \n",
        "        col_feature = [c for c in model_df.columns if c not in [col_id, col_target]]\n",
        "\n",
        "    return (model_df, col_feature, woe_map_dict)\n",
        "\n",
        "\n",
        "\n",
        "def fill_na_df(data_df, col_num, col_cat, na_val_num=0, na_val_cat='NA'):\n",
        "    data_df[col_num] = data_df[col_num].fillna(na_val_num)\n",
        "    data_df[col_cat] = data_df[col_cat].fillna(na_val_cat)    \n",
        "    return data_df\n",
        "\n",
        "\n",
        "def get_undersampled_data(data_df, col_num, col_target):\n",
        "    rus = RandomUnderSampler(sampling_strategy='auto', random_state=100)    \n",
        "    df_rus, y_rus = rus.fit_resample(data_df[col_num], data_df[col_target])  \n",
        "    df_rus[col_target] = y_rus.values\n",
        "    return df_rus     \n",
        "\n",
        "\n",
        "def get_oversampled_data(data_df, col_num, col_target):\n",
        "    ros = RandomOverSampler(sampling_strategy='auto', random_state=100)    \n",
        "    df_ros, y_ros = ros.fit_resample(data_df[col_num], data_df[col_target])  \n",
        "    df_ros[col_target] = y_ros.values\n",
        "    return df_ros    \n",
        "\n",
        "\n",
        "def get_undersampled_oversampled_data(data_df, col_num, col_target):\n",
        "    rus = RandomUnderSampler(sampling_strategy='auto', random_state=100)    \n",
        "    df_rus, y_rus = rus.fit_resample(data_df[col_num], data_df[col_target])  \n",
        "    df_rus[col_target] = y_rus.values    \n",
        "\n",
        "    ros = RandomOverSampler(sampling_strategy='auto', random_state=100)    \n",
        "    df_ros, y_ros = ros.fit_resample(data_df[col_num], data_df[col_target])  \n",
        "    df_ros[col_target] = y_ros.values\n",
        "    \n",
        "    df_output = df_rus.append(df_ros)\n",
        "    df_output.reset_index(drop=True, inplace=True)  \n",
        "    \n",
        "    return df_output    \n",
        "\n",
        "\n",
        "def get_classifier_model(data_df, col_target, col_feature, model_type):\n",
        "    model = None\n",
        "    \n",
        "    if model_type  == 'catboost':    \n",
        "        model = CatBoostClassifier(\n",
        "                                   random_seed=100,\n",
        "                                   od_type='Iter', od_wait=20, \n",
        "                                   eval_metric='AUC', \n",
        "                                   verbose = 0,                                                                 \n",
        "                                   fold_len_multiplier=2,   \n",
        "                                   allow_writing_files=False,\n",
        "                                   )   \n",
        " \n",
        "        model.fit(data_df[col_feature], data_df[col_target])\n",
        "\n",
        "\n",
        "    if model_type == 'lgb':   \n",
        "        model = get_lgb_classification_model(data_df, col_target, col_feature)\n",
        "\n",
        "    if model_type == 'glmnet':    \n",
        "        model = LogitNet()\n",
        "        model.fit(data_df[col_feature], data_df[col_target])\n",
        "\n",
        "    if model_type == 'pygam':\n",
        "        model = LogisticGAM(s(0) + s(1))             \n",
        "        lam = np.logspace(-3, 5, 5)\n",
        "        lams = [lam] * 2\n",
        "        model.gridsearch(data_df[col_feature].values, data_df[col_target].values, lam=lams)\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def decile_analysis(data_df, col_id, col_target, y_prob, y_true):\n",
        "    decile_df = data_df[[col_id, col_target]].copy()\n",
        "    decile_df['y'] = y_true\n",
        "    decile_df['y_prob'] = y_prob\n",
        "    \n",
        "    base_response_rate = 100*decile_df[decile_df.y == 1].shape[0]/decile_df.shape[0]\n",
        "    decile_df.sort_values(by = 'y_prob', inplace = True, ascending = False)\n",
        "    decile_df.reset_index(inplace = True)\n",
        "    decile_df['decile'] = np.nan\n",
        "    d = int(np.ceil(decile_df.shape[0]/10))\n",
        "    start = 0\n",
        "    end = d\n",
        "    \n",
        "    for i in range(10):\n",
        "        decile_df.loc[start:end, ['decile']] = i + 1\n",
        "        start = start + d\n",
        "        end = end + d\n",
        "        \n",
        "    decile_result_df = pd.crosstab(decile_df['decile'], decile_df['y'])\n",
        "    decile_result_df.columns = ['zero', 'one']\n",
        "    decile_result_df['min_prob'] = decile_df.groupby(by = ['decile']).min()['y_prob']\n",
        "    decile_result_df['max_prob'] = decile_df.groupby(by = ['decile']).max()['y_prob']\n",
        "    decile_result_df['count'] = decile_df.groupby(by = ['decile']).count()['y_prob']\n",
        "    decile_result_df['gain'] = np.round(100*decile_result_df['one']/decile_result_df['one'].sum(), decimals = 2)\n",
        "    decile_result_df['cum_gain'] = np.cumsum(decile_result_df['gain'])\n",
        "    decile_result_df['lift'] = np.round((100*decile_result_df['one']/decile_result_df['count'])/base_response_rate, 2)  \n",
        "    \n",
        "    return decile_result_df\n",
        "\n",
        "\n",
        "def get_validation_results(valid_date, model, model_type, col_id, col_target, col_num, col_cat, col_feature_init, feature_method, \n",
        "                           scaler, reducer, to_scale, woe_map_dict, print_output=False):\n",
        "    \n",
        "    valid_df = pd.read_csv(os.path.join(dataWorkingPath / f\"model_data_{valid_date}.csv\"))\n",
        "    valid_df = fill_na_df(valid_df, col_num, col_cat)  \n",
        "    (valid_df, _, _) = get_model_df(valid_df, col_id, col_target, col_num, col_cat, feature_method, woe_map_dict)\n",
        "\n",
        "    for col in col_feature_init:\n",
        "        if col not in valid_df.columns:\n",
        "            valid_df[col] = 0\n",
        "        \n",
        "    if to_scale:\n",
        "        valid_df[col_feature_init] = scaler.transform(valid_df[col_feature_init])        \n",
        "           \n",
        "    col_feature = col_feature_init.copy()\n",
        "    if reducer is not None:\n",
        "        col_feature_pca = [f'C{int(i)}' for i in np.arange(1,reducer.n_components_+1)]\n",
        "        valid_df = pd.concat([valid_df, pd.DataFrame(reducer.transform(valid_df[col_feature].values), columns=col_feature_pca)], axis=1)\n",
        "        col_feature = col_feature_pca.copy()\n",
        "\n",
        "    if model_type in ['catboost','glmnet']:\n",
        "        y_pred = model.predict(valid_df[col_feature])*1            \n",
        "        y_prob = model.predict_proba(valid_df[col_feature])[:, 1]                 \n",
        "    \n",
        "    elif model_type in ['lgb']:\n",
        "        y_prob = model.predict(valid_df[col_feature])           \n",
        "        y_pred = (y_prob > 0.5)*1             \n",
        "                \n",
        "    elif 'pygam' in model_type.split('-'):\n",
        "        y_pred = model.predict(valid_df[col_feature])*1            \n",
        "        y_prob = model.predict_proba(valid_df[col_feature])  \n",
        "\n",
        "\n",
        "    y_true = valid_df[col_target].values\n",
        "    decile_result_df = decile_analysis(valid_df, col_id, col_target, y_prob, y_true)   \n",
        "    classification_report_ = classification_report(y_true, y_pred, output_dict=True)\n",
        "    result_dict = {\n",
        "        f'{valid_date}_precision': np.round(classification_report_['1']['precision'], 3),\n",
        "        f'{valid_date}_recall': np.round(classification_report_['1']['recall'], 3),        \n",
        "        }\n",
        "    for i in np.arange(1,6):\n",
        "        result_dict[f\"{valid_date}_top_{i}0_gain\"] = np.round(decile_result_df.loc[int(i)]['cum_gain'],2)   \n",
        "\n",
        " \n",
        "    if print_output:\n",
        "        classification_report_ = pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).transpose().reset_index() \n",
        "        print(f\"## {valid_date}: {model_type}\")\n",
        "        print(classification_report_)\n",
        "        print()\n",
        "        print(decile_result_df)\n",
        "        print()     \n",
        "\n",
        "    return (classification_report_, decile_result_df, result_dict)\n",
        "    \n",
        "\n",
        "def convert_excel_date_to_date(excel_date):\n",
        "    return datetime.fromordinal(datetime(1900, 1, 1).toordinal() + excel_date - 2).date()"
      ],
      "metadata": {
        "id": "pT2VAcbYRHzs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_method_list = ['one_hot','woe']\n",
        "feature_selection_method_list = ['NA','fix','vif','pca']\n",
        "model_type_list = ['catboost','lgb','glmnet','pygam']\n",
        "sampling_type = ['under','over','underover']\n",
        "\n",
        "model_sampling_type_list = []\n",
        "for model_type in model_type_list:\n",
        "    model_sampling_type_list += [f\"{model_type}-{c}\" for c in sampling_type]\n",
        "\n",
        "to_scale = True\n",
        "col_cat = ['COMM_STYLE','CLAWBACK_STYLE','REGION','BENEFITCODE',\n",
        "           'gender1','SMOKER1','gender2','SMOKER2','occ_class','JOINTLIFE',\n",
        "           'BENESC','PRODCODE','prem_freq','product','rated']\n",
        "\n",
        "col_num = ['initial_sum_assured','POLTERM','UWLDPERML1_MORT','UWLDPERML2_MORT','UWPERMILL1_MORT','UWPERMILL2_MORT','age_life1','age_life2','pol_tenure']\n",
        "col_id = 'id'\n",
        "col_target = 'target'\n",
        "date_list = ['2016-06-30','2017-06-30','2018-06-30']\n",
        "\n",
        "result_df = pd.DataFrame()\n",
        "\n",
        "for feature_method in feature_method_list:\n",
        "    \n",
        "    for feature_selection_method in feature_selection_method_list:\n",
        "\n",
        "        print(f\"# feature_method: {feature_method}, feature_selection_method: {feature_selection_method}\")\n",
        "\n",
        "\n",
        "        for model_sampling_type in model_sampling_type_list:  \n",
        "            model_type = model_sampling_type.split('-')[0]\n",
        "            sampling_type = model_sampling_type.split('-')[-1]              \n",
        "            print(f\"model_type: {model_type}, sampling_type: {sampling_type}\")\n",
        "\n",
        "            out_dict = {\n",
        "                'model_type': model_type,\n",
        "                'sampling_type': sampling_type,                \n",
        "                'feature_method': feature_method,\n",
        "                'feature_selection_method': feature_selection_method,    \n",
        "                'scale': to_scale,    \n",
        "                }\n",
        "\n",
        "            for train_date, valid_date in zip(date_list[:-1], date_list[1:]):\n",
        "\n",
        "                train_df = pd.read_csv(os.path.join(dataWorkingPath / f\"model_data_{train_date}.csv\"))\n",
        "                train_df = fill_na_df(train_df, col_num, col_cat)  \n",
        "                \n",
        "                if model_type in ['glmnet','pygam']:\n",
        "                    # Apply log1p transformation to initial_sum_assured as it exhibits heavy tail\n",
        "                    train_df['initial_sum_assured'] = np.log1p(train_df['initial_sum_assured'])\n",
        "                    \n",
        "                \n",
        "                (train_df, col_feature, woe_map_dict) = get_model_df(train_df, col_id, col_target, col_num, col_cat, feature_method)\n",
        "        \n",
        "                if 'fix' in feature_selection_method.split('-'):   \n",
        "                    col_to_keep = ['CLAWBACK_STYLE','SMOKER1','age_life1','pol_tenure']\n",
        "                    col_feature = [c for c in col_feature if c.split('--')[0] in col_to_keep]\n",
        "        \n",
        "                if 'vif' in feature_selection_method.split('-'):   \n",
        "                    col_to_rm = ['BENEFITCODE','PRODCODE','BENESC']\n",
        "                    col_feature = [c for c in col_feature if c.split('--')[0] not in col_to_rm]\n",
        "                    \n",
        "                if 'finh' in feature_selection_method.split('-'):    \n",
        "                    col_feature = ypf.get_important_features(train_df, train_df[col_target], col_feature)    \n",
        "        \n",
        "                scaler = None\n",
        "                if to_scale:\n",
        "                    scaler = StandardScaler()\n",
        "                    scaler.fit(train_df[col_feature])\n",
        "                    train_df[col_feature] = scaler.transform(train_df[col_feature])\n",
        "        \n",
        "                reducer = None\n",
        "                col_feature_init = col_feature.copy()\n",
        "                if 'pca' in feature_selection_method.split('-'):  \n",
        "                    reducer = PCA(n_components=0.95, random_state=100)   \n",
        "                    reducer.fit(train_df[col_feature].values)\n",
        "\n",
        "                    col_feature_pca = [f'C{int(i)}' for i in np.arange(1,reducer.n_components_+1)]\n",
        "                    train_df = pd.concat([train_df, pd.DataFrame(reducer.transform(train_df[col_feature].values), columns=col_feature_pca)], axis=1)\n",
        "                    col_feature = col_feature_pca.copy()\n",
        "\n",
        "\n",
        "                if sampling_type == 'under':\n",
        "                    train_df_sampled = get_undersampled_data(train_df, col_feature, col_target)    \n",
        "                    \n",
        "                if sampling_type == 'over':\n",
        "                    train_df_sampled = get_oversampled_data(train_df, col_feature, col_target)                    \n",
        "                    \n",
        "                if sampling_type == 'underover':\n",
        "                    train_df_sampled = get_undersampled_oversampled_data(train_df, col_feature, col_target)                    \n",
        "                    \n",
        "                model = get_classifier_model(train_df_sampled, col_target, col_feature, model_type)\n",
        "        \n",
        "\n",
        "                (classification_report_, decile_result_df, result_dict) = get_validation_results(valid_date, model, model_type, col_id, col_target, col_num, col_cat, col_feature_init, \n",
        "                                                                                                 feature_method, scaler, reducer, to_scale, woe_map_dict)\n",
        "                out_dict.update(result_dict)\n",
        "\n",
        "            result_df = result_df.append(out_dict, ignore_index=True)\n",
        "                 \n",
        "result_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "2Fhm6jjIROUu",
        "outputId": "d1facad1-a94f-4f7f-bc66-b025b30498a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# feature_method: one_hot, feature_selection_method: NA\n",
            "model_type: catboost, sampling_type: under\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-20dcc07bd120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_date\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataWorkingPath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"model_data_{train_date}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_na_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Marco\\\\Desktop\\\\TU Dublin\\\\MSc Research Project\\\\Data/working/model_data_2016-06-30.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GTJqOQy7RWKz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}